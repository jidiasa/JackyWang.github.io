<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CS180 Project 2 by Tianhe Wang</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 20px;
        }
        h1, h2 {
            text-align: center;
        }
        img {
            display: block;
            margin: 0 auto;
            max-width: 100%;
            height: auto;
        }
        .content {
            margin-bottom: 40px;
        }
        .content p {
            margin: 15px 0;
        }
        .image-container {
            text-align: center;
            margin-bottom: 20px;
        }
        .image-container img {
            margin-bottom: 10px;
        }
    </style>
</head>
<body>

    <h1>CS180 Project 2</h1>
    <h2>Author: Tianhe Wang</h2>

    <div class="content">
        <h3>1. Part 1.1: Gradient Magnitude Image</h3>
        <p>By convolving the image with D_x and D_y, then summing the vector values of both results, we obtain the gradient magnitude image. A threshold value of 0.2 was selected, assigning 1 to values greater than 0.2, and 0 to others, resulting in a binarized edge image. The result is shown below:</p>
        <div class="image-container">
            <img src="result_img/result_1_1.png" alt="Gradient Magnitude Image">
        </div>
    </div>

    <div class="content">
        <h3>2. Part 1.2: Gaussian Blur and Edge Detection</h3>
        <p>In this part, the image is first Gaussian blurred, with a kernel size of 5 and a sigma value of 1, resulting in a slight blur. Then, the blurred image is used for the edge detection operation in part 1.1, yielding an edge image. It can be seen that the blurred image reflects the edges of the original image more clearly, with fewer noise points and wider, more defined edges. This improvement is likely because the points that were previously misidentified as edges have been smoothed out by the Gaussian kernel, effectively removing the noise. The result is shown below:</p>
        <div class="image-container">
            <img src="result_img/result_1_2.png" alt="Edge Detection after Gaussian Blur">
        </div>
        <p>Alternatively, a Gaussian kernel is first blurred and convolved with the image, yielding the same result, shown below:</p>
        <div class="image-container">
            <img src="result_img/edge_output.png" alt="Edge Detection with Gaussian Kernel">
        </div>
    </div>

    <div class="content">
        <h3>3. Part 2.1: Image Sharpening</h3>
        <p>After importing the image, the image is convolved with a Gaussian kernel to obtain the low-frequency information. Then, the low-frequency information is subtracted from the original image to obtain the high-frequency information. Finally, the high-frequency information, multiplied by a sharpening factor, is added back to the original image to produce the sharpened image. The result is shown below:</p>
        <div class="image-container">
            <img src="result_img/sharpened.png" alt="Sharpened Image">
        </div>
        <p>After sharpening, the image is blurred and then sharpened again. The result is shown below:</p>
        <div class="image-container">
            <img src="result_img/sharpened_blurred_sharpened.png" alt="Blurred and Resharpened Image">
        </div>
        <p>After sharpening, the image is blurred and then sharpened again. The sharpening factor is higher than before, but the result is not ideal. The image edges remain fairly clear, but many details are still blurry. This is because the second sharpening was performed after blurring, which removed much of the high-frequency content. While the sharpening process attempts to restore edges and details, the blurring step significantly reduced the image's high-frequency details, making the sharpening less effective than initially. The result is shown below:</p>
        <p>Other sharpened images are shown below:</p>
        <div class="image-container">
            <img src="result_img/sharpened_me.png" alt="Other Sharpened Images">
        </div>
    </div>

    <div class="content">
        <h3>4. Part 2.2: Image Hybriding</h3>
        <p>The high-frequency and low-frequency information of two images are hybrided together. The result is shown below:</p>
        <div class="image-container">
            <img src="result_img/hybrid_fail.png" alt="Image Hybriding">
        </div>
        <p>It can be observed that for the first image, the picture is tilted, and the face does not stand out against the background; only the teeth and eyes are visible, resulting in an unsatisfactory fusion of the face and the cat's face. Here, I adjusted the high-frequency information of the image by increasing the color contrast of the high-frequency information, making it more prominent in the image. Below are two more successful cases: the fusion of a car and a leopard, and the fusion of Taylor and Ed.</p>
        <div class="image-container">
            <img src="result_img/car-animal.png" alt="Car and Leopard Fusion">
            <img src="result_img/Taylor-ed.png" alt="Taylor and Ed Fusion">
        </div>
        <p>The fusion result of the car and the leopard is my favorite outcome. The original images, the images obtained after extracting the low-frequency or high-frequency information, and the fused image were all subjected to Fourier transformation to obtain the spectrum diagrams. The results are shown below:</p>
        <div class="image-container">
            <img src="result_img/hybrid_fre.png" alt="Fourier Spectrum">
            <img src="result_img/hybrid.png" alt="Fourier Spectrum">
        </div>
    </div>

    <div class="content">
        <h3>5. Part 2.3: Gaussian and Laplacian Pyramid</h3>
        <p>For part 2.3, the image is convolved with a Gaussian kernel to obtain a blurred image. This step is repeated to continuously generate images with increasing levels of blur, ultimately forming a Gaussian pyramid. The adjacent layers of the Gaussian pyramid are then subtracted to obtain the Laplacian pyramid of the image. The results are shown below:</p>
        <div class="image-container">
            <img src="result_img/pyramids.jpg" alt="Laplacian Pyramid">
        </div>
    </div>

    <div class="content">
        <h3>6. Part 2.4: Multiresolution Blending</h3>
        <p>Using the Laplacian pyramid, the images are blended layer by layer. The result is shown below:</p>
        <div class="image-container">
            <img src="result_img/apple_orange.png" alt="Multiresolution Blending">
        </div>
        <p>Using the same mask, the blending of two faces can be achieved. The result is shown below:</p>
        <div class="image-container">
            <img src="result_img/blend_wu.png" alt="Face Blending">
        </div>
        <p>Face recognition is performed on the two input facial images using OpenCV's Haar feature function. Based on the detected faces, the two images are cropped to the same size, ensuring that the dividing line between the left and right sides of the face aligns with the center line of the image, facilitating subsequent face blending.</p>
        <p>Below is an example using a mask of different shapes, where my hand and mouth are fused together. An elliptical mask was chosen for this purpose, and the result is shown below:</p>
        <div class="image-container">
            <img src="result_img/blend_face_mouth.png" alt="hand-mouth blending">
        </div>
    </div>

</body>
</html>
